{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afcab5bc-e7e6-4c48-965d-71854d4bc373",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54da99a-2e9b-4beb-a25e-382ff7ba5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_audio(audio_path, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Vorverarbeitung einer Audiodatei: Resampling und Normalisierung.\n",
    "\n",
    "    Args:\n",
    "        audio_path (str): Pfad zur Audiodatei.\n",
    "        sample_rate (int): Ziel-Sampling-Rate (Standard: 16000).\n",
    "\n",
    "    Returns:\n",
    "        np.array: Das vorverarbeitete Audio-Signal.\n",
    "    \"\"\"\n",
    "    # Audiodatei laden und resamplen\n",
    "    audio_signal, _ = librosa.load(audio_path, sr=sample_rate)\n",
    "\n",
    "    # Zu Mono konvertieren (falls mehrkanalig)\n",
    "    audio_signal = librosa.to_mono(audio_signal)\n",
    "\n",
    "    # Normalisieren\n",
    "    max_val = np.max(np.abs(audio_signal))\n",
    "    if max_val > 0:\n",
    "        audio_signal = audio_signal / max_val\n",
    "\n",
    "    return audio_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b13cf9-8ad8-4016-9c6b-2cedd930bf24",
   "metadata": {},
   "source": [
    "# Funktion phoneme entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05568daa-108c-4e8d-a6aa-0d3e5f8d5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def calculate_phoneme_entropy(audio_signal, sample_rate=16000, frame_length=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Berechnet die Phoneme Entropy eines Audiosignals basierend auf der spektralen Energieverteilung.\n",
    "\n",
    "    Quelle:\n",
    "        Jelinek, F. (1997). Statistical Methods for Speech Recognition.\n",
    "        MIT Press.\n",
    "\n",
    "    Args:\n",
    "        audio_signal (np.array): Das normalisierte Audio-Signal (1D-Array).\n",
    "        sample_rate (int): Sampling-Rate des Signals (Standard: 16000 Hz).\n",
    "        frame_length (int): Länge eines FFT-Frames in Samples (Standard: 2048).\n",
    "        hop_length (int): Schrittweite zwischen Frames in Samples (Standard: 512).\n",
    "\n",
    "    Returns:\n",
    "        float: Phoneme Entropy-Wert für das gesamte Signal.\n",
    "    \"\"\"\n",
    "    # Falls das Signal zu leise oder konstant ist, Entropie auf 0 setzen\n",
    "    if np.all(audio_signal == audio_signal[0]):\n",
    "        return 0.0\n",
    "\n",
    "    # Berechnung des Leistungsverhältnisses (Power Spectrogram)\n",
    "    spectrogram = np.abs(librosa.stft(audio_signal, n_fft=frame_length, hop_length=hop_length)) ** 2\n",
    "\n",
    "    # Normalisierung über die Frequenzbänder (damit die Summe 1 ergibt)\n",
    "    prob_distribution = spectrogram / np.sum(spectrogram, axis=0, keepdims=True)\n",
    "\n",
    "    # Berechnung der Entropie pro Frame (log2, um Bits als Einheit zu haben)\n",
    "    entropy_per_frame = -np.sum(prob_distribution * np.log2(prob_distribution + 1e-10), axis=0)\n",
    "\n",
    "    # Mittelwert über alle Frames\n",
    "    entropy_value = np.mean(entropy_per_frame)\n",
    "\n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b65b3-e07a-4c9f-9d39-d52ccb389eb7",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e451991-8ef8-49fa-8937-e13f4885ef38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme Entropy (_noise_pink.wav): 6.8861\n",
      "Phoneme Entropy (_noise_white.wav): 9.3703\n",
      "Phoneme Entropy (_signal_constant.wav): 0.0000\n",
      "Phoneme Entropy (_signal_silence.wav): 0.0000\n",
      "Phoneme Entropy (_signal_sine.wav): 1.3561\n",
      "Phoneme Entropy (_snr_03.wav): 5.6221\n",
      "Phoneme Entropy (_snr_10.wav): 5.4378\n",
      "Phoneme Entropy (_snr_20.wav): 5.0564\n",
      "Phoneme Entropy (example1.wav): 3.9807\n",
      "Phoneme Entropy (example2.wav): 3.9538\n",
      "Phoneme Entropy (example3.wav): 4.4790\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Phoneme Entropy für alle Dateien berechnen\n",
    "for file_name in sorted(os.listdir(\"../audio_files\")):  # Alphabetische Sortierung\n",
    "    if file_name.endswith(\".wav\"):\n",
    "        file_path = os.path.join(\"../audio_files\", file_name)\n",
    "\n",
    "        # Audiodatei vorverarbeiten\n",
    "        audio_signal = preprocess_audio(file_path)\n",
    "\n",
    "        # Phoneme Entropy berechnen\n",
    "        entropy_value = calculate_phoneme_entropy(audio_signal)\n",
    "\n",
    "        print(f\"Phoneme Entropy ({file_name}): {entropy_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
